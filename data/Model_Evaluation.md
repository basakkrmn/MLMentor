# Model Evaluation and Validation

Evaluating machine learning models ensures they **generalize well** to unseen data.

## Key Metrics

- **Accuracy:** Fraction of correct predictions.
- **Precision:** Correct positive predictions divided by all predicted positives.
- **Recall (Sensitivity):** Correct positive predictions divided by actual positives.
- **F1-Score:** Harmonic mean of precision and recall.
- **ROC-AUC:** Measures performance across all classification thresholds.

## Validation Techniques
- **Train/Test Split:** Split data into training and testing sets (e.g., 80/20).
- **Cross-Validation:** K-fold cross-validation averages performance across K splits.
- **Confusion Matrix:** Shows TP, TN, FP, FN for classification tasks.

## Concepts
- **Overfitting:** Model memorizes training data.
- **Underfitting:** Model is too simple to capture data patterns.
- **Bias-Variance Tradeoff:** Balance between error from bias and error from variance.
